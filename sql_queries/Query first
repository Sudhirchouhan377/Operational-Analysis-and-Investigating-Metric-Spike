
job_data table with the following columns:
● job_id: Unique identifier of jobs 
● actor_id: Unique identifier of actor 
● event: The type of event (decision/skip/transfer). 
● language: The Language of the content 
● time_spent: Time spent to review the job in seconds. 
● org: The Organization of the actor 
● ds: The date in the format yyyy/mm/dd (stored as text)


Table Name : job_data

A) Jobs Reviewed Over Time:

select 
ds as review_date,
time_spent as review_hour,
count(job_id) as job_reviewed
from job_data 
where ds>= '2020-11-01' AND ds <= '2020-11-30'
group by review_date ,review_hour 
order by review_date , review_hour; 
Output:


B) Throughput Analysis:


with daily_throughput as (
select ds as review_date,
count(job_id) as jobs_reviewed
from job_data
group by ds
)
select review_date,
jobs_reviewed,
avg(jobs_reviewed) over(
1. 
2. 
3. 
4. 
order by review_date
rows between 6 preceding and current row
) as rolling_avg_7_days
from daily_throughput
order by review_date;



C) Language Share Analysis:

   
WITH last_30_days_jobs AS (
SELECT
language,
COUNT(*) AS jobs_count
FROM job_data
WHERE ds BETWEEN '2020-11-01' AND '2020-11-30'
GROUP BY language
),
total_jobs AS (
SELECT SUM(jobs_count) AS total_jobs_count
FROM last_30_days_jobs
)
SELECT l.language,
l.jobs_count,
ROUND((l.jobs_count / t.total_jobs_count) * 100, 2) AS percentage_share
FROM
last_30_days_jobs l,
total_jobs t
ORDER BY
percentage_share DESC;



D) Duplicate Rows Detection:
Objective: Identify duplicate rows in the data. 
Your Task: Write an SQL query to display duplicate rows from the job_data table.
Code:
select ds, job_id , event, language , time_spent , org
from job_data
group by ds , job_id , event , language , time_spent , org
having count(*)>1;
select ds,
job_id,
actor_id,
event,
language,
time_spent,
org
from job_data
group by ds,job_id,actor_id,event,language,time_spent,org
having count(*)>1;

